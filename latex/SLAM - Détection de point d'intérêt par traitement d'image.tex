\documentclass[conference,compsoc]{IEEEtran}
\usepackage{smartdiagram}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}
% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi


\usepackage[cmex10]{amsmath}

\usepackage{lipsum} % for filling with text (demo)

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% Keywords command
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{State of art : Visual Assistant}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Zacharia Azzouzi}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: zacharia.azzouziclausel@viacesi.fr}
\and
\IEEEauthorblockN{RÃ©mi Papin}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: remi.papin@viacesi.fr}
\linebreakand
\IEEEauthorblockN{Fabien Richard}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: fabien.richard1@viacesi.fr}
\and
\IEEEauthorblockN{Guillaume Woreth}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: guillaume.woreth@viacesi.fr}
}
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
In the context of helping the visually impaired this document will talk about technologies capable of reading documents, counting peoples, detecting pedestrians vehicle and signage. We compare our project with existing implementation like glasses produced by the company OrCam or the EVA project.
The objective of our research team is to train on this technology and to add the detection of dynamic objects. Calculation of the speed and estimation of the possibility of interaction with other persons or not.
\end{abstract}
\hspace{10pt}

% keywords
\keywords{Computer vision, SLAM, DATMO, MOT, Visual Assistant}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For preview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
SLAM (Simultaneous Localization and Mapping) \cite{mozos2007interest} methods make it possible to estimate both the trajectory of a blind person and the structure of the world from data acquired from an on-board sensor. The goal is to produce from visual data of a dynamic scene a description usable by an information system: modeling of the static world, location of the human in this world, and how other mobile objects move there. An approach combining Segmentation by Clustering and Classification makes it possible to detect on the one hand static points taken into account in visual SLAM, and on the other hand groups of mobile points used to detect and follow the dynamic components of the scene. The overall approach is assessed on the basis of images acquired in an urban environment \cite{gil2010comparative}.

\section{Project}
There are technologies capable of reading documents, language support, technology miniaturization, counts the number of people, helps to see situations on screens, currency and face recognition, able to detect pedestrians vehicle and signage or again to driving assistance. This implementation already exists in the form of glasses produced by the company OrCam \cite{orcam_2021} or in the EVA project \cite{eva}.
The objective of our research team is to train on this technology and to add the detection of dynamic objects. Calculation of the speed and estimation of the possibility of contact with the person or not.
To meet our needs, we will use existing SLAM and DATMO (for Detection and Tracking of Moving Object) \cite{Pancham2011-11} technologies. In addition, we will implement Artificial Intelligence to perform model recognition from a collaborative database, allowing us to rapidly increase our datasets and offer a more efficient solution and implement more 'tools to increase the autonomy of blind and partially sighted people.
In 2016, JAMA Ophthalmology \cite{adrienne_w.scott_2016} conducted a study involving 12 legally blind participants to assess the usefulness of a portable artificial vision device (OrCam) for visually impaired patients. The results showed that the OrCam \cite{orcam_2021} device would improve the patient's ability to perform tasks simulating those of daily living, such as reading a message on an electronic device, a newspaper article or a menu.
The Orcam \cite{orcam_2021} project still contains many limitations such as reading non-handwritten text as well as battery autonomy.
 
The EU-funded EVA project \cite{eva} has developed voice-activated glasses for the visually impaired. EVA, the acronym for "Extended Visual Assistant" or "Extended Visual Assistant", is based on a machine vision system that recognizes objects, text and signs and orally describes what it sees. These glasses have the advantages of being light and discreet.

The EVA project \cite{eva} still contains many limitations such as a mandatory connection to a smartphone, the use of the smartphone speaker, constraint in a street with a lot of noise, it is also a very expensive technology.

\begin{figure}[ht]
\centering
\scalebox{0.6}{
\smartdiagram[circular diagram]{User moving,
  Identification, Calculation of collision, Warning}}
\caption{Visual assistant operating diagram.}
\end{figure}

\section{Application to our project}
In this article, we consider that there may be moving objects in the human perceived world; despite this, we want to solve the problem of SLAM, and at the same time, estimate the state of each moving object. This also requires addressing the detection and tracking of these moving objects, while retaining the ability to detect a sufficient number of fixed landmarks in order to locate the human.


\section{Conclusion}

In this article we have presented a system that effectively addresses the problem of navigation in dynamic environments for blind people.

We have also achieved the state of the art at the level of our competitors in order to clear their limits.
We have therefore defined the main technical evolutions that we are going to implement in our beta product.

The goal is to release a first product with features that our competitors already have (Proof of Concept).

This first product (Beta), will have the following features:
\begin{itemize}
\item An on-board system which attaches to glasses and does not require a smartphone
\item Bone conduction headphones.
\item Marker in space and vocal guide.
\item Voice and gestural interaction with the product.
\end{itemize}

Secondly, after having produced our beta product, we will focus on producing a range of products (three in number):
\begin{itemize}
\item Product 1: this product contains all the basic functionalities (SLAM / Document reading (multilingual))
\item Product 2: this product contains all the basic functionalities as well as more advanced functionalities:
\begin{itemize}
    \item Integrates the functions of version 1;
    \item Languages and text translation;
    \item Face emotion;
    \item Brand identification and Identify popular places.
    \end{itemize}
\end{itemize}



\bibliographystyle{IEEEtran}
%\nocite{*} % to show every citations, even the ones which are not cited
\bibliography{biblio}
\end{document}
