\documentclass[conference,compsoc]{IEEEtran}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}
% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
\usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex

\usepackage[cmex10]{amsmath}

\usepackage{lipsum} % for filling with text (demo)

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% Keywords command
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{State of art : SLAM - Point of interest detection by image processing}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Zacharia Azzouzi}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: zacharia.azzouziclausel@viacesi.fr}
\and
\IEEEauthorblockN{RÃ©mi Papin}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: remi.papin@viacesi.fr}
\and
\IEEEauthorblockN{Fabien Richard}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: fabien.richard1@viacesi.fr}
\and
\IEEEauthorblockN{Guillaume Woreth}
\IEEEauthorblockA{School of CESI\\Computer Engineering\\
Lyon, France\\
Email: guillaume.woreth@viacesi.fr}
}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
In the context of helping the visually impaired. There are technologies capable of reading documents, language support, counts the number of people, helps to see situations on screens, currency and face recognition, able to detect pedestrians vehicle and signage or again to driving assistance. This implementation already exists in the form of glasses produced by the company OrCam \cite{orcam_2021} or in the EVA project \cite{eva}.
The objective of our research team is to train on this technology and to add the detection of dynamic objects. Calculation of the speed and estimation of the possibility of contact with the person or not.
\end{abstract}
\hspace{10pt}

% keywords
\keywords{computer vision, slam, datmo, mot}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For preview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
SLAM (Simultaneous Localization and Mapping) \cite{mozos2007interest} methods make it possible to estimate both the trajectory of a blind person and the structure of the world from data acquired from an on-board sensor. The goal is to produce from visual data of a dynamic scene a description usable by an information system: modeling of the static world, location of the human in this world, and how other mobile objects move there. An approach combining Segmentation by Clustering and Classification makes it possible to detect on the one hand static points taken into account in visual SLAM, and on the other hand groups of mobile points used to detect and follow the dynamic components of the scene. The overall approach is assessed on the basis of images acquired in an urban environment \cite{gil2010comparative}.

\section{Project}
In the context of helping the visually impaired. There are technologies capable of reading documents, language support, technology miniaturization, counts the number of people, helps to see situations on screens, currency and face recognition, able to detect pedestrians vehicle and signage or again to driving assistance. This implementation already exists in the form of glasses produced by the company OrCam \cite{orcam_2021} or in the EVA project \cite{eva}.
The objective of our research team is to train on this technology and to add the detection of dynamic objects. Calculation of the speed and estimation of the possibility of contact with the person or not.
To meet our needs, we will use existing SLAM and DATMO (for Detection and Tracking of Moving Object) \cite{Pancham2011-11} technologies. In addition, we will implement Artificial Intelligence to perform model recognition from a collaborative database, allowing us to rapidly increase our datasets and offer a more efficient solution and implement more 'tools to increase the autonomy of blind and partially sighted people.
In 2016, JAMA Ophthalmology conducted a study involving 12 legally blind participants to assess the usefulness of a portable artificial vision device (OrCam) for visually impaired patients. The results showed that the OrCam \cite{orcam_2021} device would improve the patient's ability to perform tasks simulating those of daily living, such as reading a message on an electronic device, a newspaper article or a menu.
The Orcam \cite{orcam_2021} project still contains many limitations such as reading non-handwritten text as well as battery autonomy.
 
The EU-funded EVA project \cite{eva} has developed voice-activated glasses for the visually impaired. EVA, the acronym for "Extended Visual Assistant" or "Extended Visual Assistant", is based on a machine vision system that recognizes objects, text and signs and orally describes what it sees. These glasses have the advantages of being light and discreet.

The EVA project \cite{eva} still contains many limitations such as a mandatory connection to a smartphone, the use of the smartphone speaker, constraint in a street with a lot of noise, it is also a very expensive technology.

\subsection{Application to our project}
In this article, we consider that there may be moving objects in the human perceived world; despite this, we want to solve the problem of SLAM, and at the same time, estimate the state of each moving object. This also requires addressing the detection and tracking of these moving objects, while retaining the ability to detect a sufficient number of fixed landmarks in order to locate the human.


\section{Conclusion}
In this article we have presented a system that effectively addresses the problem of navigation in dynamic environments for blind people.

We have also achieved the state of the art of our competitors in order to go beyond their limits.
We have therefore defined the main technical evolutions that we are going to implement in our product:
\begin{itemize}
  \item Detect people's feelings
  \item Read non-handwritten text (50 languages)
  \item Identify popular places and product logos
  \item Implement a significant number of languages in order to be able to distribute our product throughout the world
  \item An embedded system which attaches to glasses and which does not require a smartphone
Lightweight, comfortable and stylish product
  \item Voice interaction with the product
  \item Real-time lyrics translation
  \item Bone conduction headphones
\end{itemize}


% conference papers do not normally have an appendix

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
%\nocite{*} % to show every citations, even the ones which are not cited
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{biblio}
%
% 

% that's all folks
\end{document}


